{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-benchmark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.781548Z",
     "start_time": "2021-04-19T12:07:18.089272Z"
    },
    "id": "aquatic-benchmark"
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import os\n",
    "import ctypes\n",
    "import numpy as np\n",
    "from picosdk.ps4000a import ps4000a as ps\n",
    "import matplotlib.pyplot as plt\n",
    "from picosdk.functions import adc2mV, assert_pico_ok\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter, freqz, medfilt, hann, convolve, welch, get_window, tukey, gaussian, hilbert, iirfilter\n",
    "from scipy.misc import electrocardiogram\n",
    "from scipy.signal import find_peaks\n",
    "import random\n",
    "import itertools\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from scipy.optimize import minimize\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import randn\n",
    "import scipy.stats\n",
    "from scipy.spatial.distance import cdist\n",
    "import ipympl as ipy\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "from datetime import datetime\n",
    "import serial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-functionality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.796854Z",
     "start_time": "2021-04-19T12:07:18.784085Z"
    },
    "id": "rotary-functionality"
   },
   "outputs": [],
   "source": [
    "                                          #--------------Global variables--------------#\n",
    "channelA = np.array([])\n",
    "channelB = np.array([])\n",
    "channelC = np.array([])\n",
    "channelD = np.array([])\n",
    "channelE = np.array([])\n",
    "\n",
    "Ox =  np.array([])\n",
    "Oy =  np.array([])\n",
    "Oz =  np.array([])\n",
    "Ax =  np.array([])\n",
    "Ay =  np.array([])\n",
    "Az =  np.array([])\n",
    "\n",
    "T = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-discussion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.811804Z",
     "start_time": "2021-04-19T12:07:18.798782Z"
    },
    "id": "monthly-discussion"
   },
   "outputs": [],
   "source": [
    "def gps_solve(distances_to_station, stations_coordinates):\n",
    "    def error(x, c, r):\n",
    "        return sum([(np.linalg.norm(x - c[i]) - r[i]) ** 2 for i in range(len(c))])\n",
    "\n",
    "    l = len(stations_coordinates)\n",
    "    S = sum(distances_to_station)\n",
    "    # compute weight vector for initial guess\n",
    "    W = [((l - 1) * S) / (S - w) for w in distances_to_station]\n",
    "    # get initial guess of point location\n",
    "    x0 = sum([W[i] * stations_coordinates[i] for i in range(l)])\n",
    "    # optimize distance from signal origin to border of spheres\n",
    "    return minimize(error, x0, args=(stations_coordinates, distances_to_station), method='Nelder-Mead').x\n",
    "\n",
    "# Pinger co-ordinates = [1 ,1, 1]\n",
    "# Location of hdphones = [1.70,0.0, 0.75] , [0.80, 8.85, 0.25], [0.0, 4.25, 0.55], [3.0, 4.50, 1.20]\n",
    "# Radius of spheres = [1.2459, 7.8882, 3.4300, 4.0360] #respectively\n",
    "\n",
    "    landmarks = np.array([[1.70, 0.0, 0.75], [0.80, 8.85, 0.25], [0.0, 4.25, 0.55], [3.0, 4.50, 1.20]])\n",
    "\n",
    "    H1 = landmarks[0]\n",
    "    H2 = landmarks[1]\n",
    "    H3 = landmarks[2]\n",
    "    H4 = landmarks[3]\n",
    "\n",
    "    d1 = dist_AB\n",
    "    d2 = dist_AC\n",
    "    d3 = dist_AD\n",
    "    d4 = dist_AE\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        stations = list(np.array([H1, H2, H3, H4]))\n",
    "        distances_to_station = [d1, d2, d3, d4]\n",
    "        print('\\n')\n",
    "        print(gps_solve(distances_to_station, stations))\n",
    "        print('\\033[95m' + 'Co-ordinates of the pinger = [ 0.0  0.65  1.0 ]' + '\\033[95m')\n",
    "        print ('\\033[0m')\n",
    "        pinger_coordinates_multi = gps_solve(distances_to_station, stations)\n",
    "        \n",
    "    return pinger_coordinates_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-collection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.826884Z",
     "start_time": "2021-04-19T12:07:18.814202Z"
    },
    "id": "offshore-collection"
   },
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = iirfilter(order, [low, high],\n",
    "                        btype='bandpass', ftype='butter')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    signal = lfilter(b, a, data)\n",
    "    return signal\n",
    "\n",
    "# definition for signal normalisation in range -1 to +1\n",
    "def normalisation(signal):\n",
    "    signal = signal - signal.mean()\n",
    "    signal = signal / signal.max()\n",
    "    return signal\n",
    "\n",
    "def filter_bandpass(signal, fs):\n",
    "    lowcut = 43e3\n",
    "    highcut = 47e3\n",
    "    signal = np.array(signal)\n",
    "    signal = butter_bandpass_filter(signal, lowcut, highcut, fs, order=6)\n",
    "    signal_p = normalisation(signal)\n",
    "    return signal_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-newark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.842117Z",
     "start_time": "2021-04-19T12:07:18.827920Z"
    },
    "id": "choice-newark"
   },
   "outputs": [],
   "source": [
    "from numpy.random import uniform\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 5))\n",
    "    particles[:, 0] = mean[0] + (randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (randn(N) * std[1])\n",
    "    particles[:, 2] = mean[2] + (randn(N) * std[2])\n",
    "    particles[:, 3] = mean[3] + (randn(N) * std[3])\n",
    "    particles[:, 3] %= 2 * np.pi\n",
    "    particles[:, 4] = mean[4] + (randn(N) * std[4])\n",
    "    particles[:, 4] %= 2 * np.pi\n",
    "    return particles\n",
    "\n",
    "\n",
    "def create_uniform_particles(x_range, y_range, z_range, xy_heading, z_heading, N):\n",
    "    particles = np.empty((N, 5))\n",
    "    particles[:, 0] = uniform(x_range[0], x_range[1], size=N)                 #-----X-----#\n",
    "    particles[:, 1] = uniform(y_range[0], y_range[1], size=N)                 #-----Y-----#\n",
    "    particles[:, 2] = uniform(z_range[0], z_range[1], size=N)                 #-----Z-----#\n",
    "    particles[:, 3] = uniform(xy_heading[0], xy_heading[1], size=N)\n",
    "    particles[:, 3] = particles[:, 3] % 2 * np.pi                             #-----heading in XY plane wrt X axis-----#\n",
    "    particles[:, 4] = uniform(z_heading[0], z_heading[1], size=N)\n",
    "    particles[:, 4] = particles[:, 4] % 2 * np.pi                             #-----heading wrt Z axis-----#\n",
    "    return particles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-multiple",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.858255Z",
     "start_time": "2021-04-19T12:07:18.844121Z"
    },
    "id": "norman-multiple"
   },
   "outputs": [],
   "source": [
    "def predict(particles, u, std, dt=1.):\n",
    "\n",
    "    N = len(particles)\n",
    "    # update heading\n",
    "    particles[:, 3] += u[0] \n",
    "    particles[:, 3] %= 2 * np.pi\n",
    "    particles[:, 4] = particles[:, 4] + u[1]\n",
    "    particles[:, 4] %= 2 * np.pi\n",
    "    \n",
    "    # move in the (noisy) commanded direction\n",
    "    \n",
    "    particles[:, 0] = (particles[:, 0]) + ( u[2] * math.sin(u[1]) * math. cos(u[0]) )\n",
    "    particles[:, 1] = (particles[:, 1]) + ( u[2] * math.sin(u[1]) * math. sin(u[0]) )\n",
    "    particles[:, 2] = (particles[:, 2]) + ( u[2] * math.cos(u[1]) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-plastic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.874060Z",
     "start_time": "2021-04-19T12:07:18.860176Z"
    },
    "id": "amended-plastic"
   },
   "outputs": [],
   "source": [
    "def correct(N, particles, pinger_coordinates_multi):                     #---------------Not in use---------------#\n",
    "    thetaX = np.empty((N))\n",
    "    distance = np.linalg.norm(particles[:, 0:3] - pinger_coordinates_multi, axis=1)\n",
    "    pinger_coordinates_multi = pinger_coordinates_multi.astype('float64')\n",
    "    theta_X = np.arctan((pinger_coordinates_multi[1]-particles[:, 1])/(pinger_coordinates_multi[0]- particles[:, 0]))\n",
    "    \n",
    "    a = pinger_coordinates_multi[0]-particles[:, 0]\n",
    "    b = pinger_coordinates_multi[1]-particles[:, 1]\n",
    "    c = pinger_coordinates_multi[2]-particles[:, 2]\n",
    "    mod = np.abs(np.sqrt(a**2 +b**2 +c**2))\n",
    "    theta_Z = np.arccos(c/(mod))\n",
    "    \n",
    "    \n",
    "    particles[:, 0] = (particles[:, 0]) + ( 0.25*distance[:] * np.cos(theta_X[:]))\n",
    "    particles[:, 1] = (particles[:, 1]) + ( 0.25*distance[:] * np.sin(theta_X[:]))\n",
    "    particles[:, 2] = (particles[:, 2]) + ( 0.25*distance[:] * np.sin(theta_Z[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-lounge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.890028Z",
     "start_time": "2021-04-19T12:07:18.875381Z"
    },
    "id": "bound-lounge"
   },
   "outputs": [],
   "source": [
    "def update(particles, weights, z, R, landmarks):                                      \n",
    "    for i, landmark in enumerate(landmarks):\n",
    "        distance = np.linalg.norm(particles[:, 0:3] - landmark, axis=1)   \n",
    "        weights *= scipy.stats.norm(distance, R).pdf(z[i])\n",
    "\n",
    "    weights += 1.e-300      # avoid round-off to zero\n",
    "    weights /= sum(weights) # normalize       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-jesus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:18.905850Z",
     "start_time": "2021-04-19T12:07:18.893057Z"
    },
    "id": "meaning-jesus"
   },
   "outputs": [],
   "source": [
    "def estimate(particles, weights):\n",
    "    \"\"\"returns mean and variance of the weighted particles\"\"\"\n",
    "\n",
    "    pos = particles[:, 0:5]                                              \n",
    "    mean = np.average(pos, weights=weights, axis=0)\n",
    "    var  = np.average((pos - mean)**2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "def neff(weights):                                                                     #------Unchanged cell------#\n",
    "    return 1. / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    particles[:] = particles[indexes]\n",
    "    weights.resize(len(particles))\n",
    "    weights.fill (1.0 / len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-technology",
   "metadata": {
    "id": "conscious-technology"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-benjamin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:07:21.686727Z",
     "start_time": "2021-04-19T12:07:18.907830Z"
    },
    "id": "affiliated-benjamin"
   },
   "outputs": [],
   "source": [
    "# Create chandle and status ready for use\n",
    "chandle = ctypes.c_int16()\n",
    "status = {}\n",
    "\n",
    "# Open PicoScope 4000 Series device\n",
    "# Returns handle to chandle for use in future API functions\n",
    "status[\"openunit\"] = ps.ps4000aOpenUnit(ctypes.byref(chandle), None)\n",
    "\n",
    "\n",
    "try:\n",
    "    assert_pico_ok(status[\"openunit\"])\n",
    "    print('open unit done')\n",
    "except:\n",
    "\n",
    "    powerStatus = status[\"openunit\"]\n",
    "\n",
    "    if powerStatus == 286:\n",
    "        status[\"changePowerSource\"] = ps.ps4000aChangePowerSource(chandle, powerStatus)\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "    assert_pico_ok(status[\"changePowerSource\"])\n",
    "\n",
    "\n",
    "enabled = 1\n",
    "disabled = 0\n",
    "analogue_offset = 0.0\n",
    "\n",
    "# Set up channel A\n",
    "# handle = chandle\n",
    "# channel = PS4000A_CHANNEL_A = 0\n",
    "# enabled = 1\n",
    "# coupling type = PS4000A_DC = 1\n",
    "# range = PS4000A_2V = 7\n",
    "# analogue offset = 0 V\n",
    "channel_range = 7\n",
    "status[\"setChA\"] = ps.ps4000aSetChannel(chandle,\n",
    "                                        ps.PS4000A_CHANNEL['PS4000A_CHANNEL_A'],\n",
    "                                        enabled,\n",
    "                                        ps.PS4000A_COUPLING['PS4000A_DC'],\n",
    "                                        channel_range,\n",
    "                                        analogue_offset)\n",
    "assert_pico_ok(status[\"setChA\"])\n",
    "\n",
    "# Set up channel B\n",
    "# handle = chandle\n",
    "# channel = PS4000A_CHANNEL_B = 0\n",
    "# enabled = 1\n",
    "# coupling type = PS4000A_DC = 1\n",
    "# range = PS4000A_2V = 7\n",
    "# analogue offset = 0 V\n",
    "channel_range = 7\n",
    "status[\"setChB\"] = ps.ps4000aSetChannel(chandle,\n",
    "                                        ps.PS4000A_CHANNEL['PS4000A_CHANNEL_B'],\n",
    "                                        enabled,\n",
    "                                        ps.PS4000A_COUPLING['PS4000A_DC'],\n",
    "                                        channel_range,\n",
    "                                        analogue_offset)\n",
    "assert_pico_ok(status[\"setChB\"])\n",
    "\n",
    "# Set up channel C\n",
    "# handle = chandle\n",
    "# channel = PS4000A_CHANNEL_C = 2\n",
    "# enabled = 1\n",
    "# coupling type = PS4000A_DC = 1\n",
    "# range = PS4000A_2V = 7\n",
    "# analogue offset = 0 V\n",
    "channel_range = 7\n",
    "status[\"setChC\"] = ps.ps4000aSetChannel(chandle,\n",
    "                                        ps.PS4000A_CHANNEL['PS4000A_CHANNEL_C'],\n",
    "                                        enabled,\n",
    "                                        ps.PS4000A_COUPLING['PS4000A_DC'],\n",
    "                                        channel_range,\n",
    "                                        analogue_offset)\n",
    "assert_pico_ok(status[\"setChC\"])\n",
    "\n",
    "\n",
    "# Set up channel D\n",
    "# handle = chandle\n",
    "# channel = PS4000A_CHANNEL_D = 3\n",
    "# enabled = 1\n",
    "# coupling type = PS4000A_DC = 1\n",
    "# range = PS4000A_2V = 7\n",
    "# analogue offset = 0 V\n",
    "channel_range = 7\n",
    "status[\"setChD\"] = ps.ps4000aSetChannel(chandle,\n",
    "                                        ps.PS4000A_CHANNEL['PS4000A_CHANNEL_D'],\n",
    "                                        enabled,\n",
    "                                        ps.PS4000A_COUPLING['PS4000A_DC'],\n",
    "                                        channel_range,\n",
    "                                        analogue_offset)\n",
    "assert_pico_ok(status[\"setChD\"])\n",
    "\n",
    "\n",
    "# Set up channel E\n",
    "# handle = chandle\n",
    "# channel = PS4000A_CHANNEL_A = 4\n",
    "# enabled = 1\n",
    "# coupling type = PS4000A_DC = 1\n",
    "# range = PS4000A_2V = 7\n",
    "# analogue offset = 0 V\n",
    "channel_range = 7\n",
    "status[\"setChE\"] = ps.ps4000aSetChannel(chandle,\n",
    "                                        ps.PS4000A_CHANNEL['PS4000A_CHANNEL_E'],\n",
    "                                        enabled,\n",
    "                                        ps.PS4000A_COUPLING['PS4000A_DC'],\n",
    "                                        channel_range,\n",
    "                                        analogue_offset)\n",
    "assert_pico_ok(status[\"setChE\"])\n",
    "\n",
    "# Size of capture, repetation rate should be 0.5 seconds.\n",
    "sizeOfOneBuffer = 10000\n",
    "numBuffersToCapture = 50                                                       \n",
    "# Capturing for 1 Sec with 1000*1000, for 0.5 sec divide one of them by 2\n",
    "totalSamples = sizeOfOneBuffer * numBuffersToCapture\n",
    "\n",
    "# Create buffers ready for assigning pointers for data collection\n",
    "bufferAMax = np.zeros(shape=sizeOfOneBuffer, dtype=np.int16)\n",
    "bufferBMax = np.zeros(shape=sizeOfOneBuffer, dtype=np.int16)\n",
    "bufferCMax = np.zeros(shape=sizeOfOneBuffer, dtype=np.int16)\n",
    "bufferDMax = np.zeros(shape=sizeOfOneBuffer, dtype=np.int16)\n",
    "bufferEMax = np.zeros(shape=sizeOfOneBuffer, dtype=np.int16)\n",
    "\n",
    "memory_segment = 0\n",
    "\n",
    "\n",
    "def streaming_callback(handle, noOfSamples, startIndex, overflow, triggerAt, triggered, autoStop, param):\n",
    "    global nextSample, autoStopOuter, wasCalledBack\n",
    "    wasCalledBack = True\n",
    "    destEnd = nextSample + noOfSamples\n",
    "    sourceEnd = startIndex + noOfSamples\n",
    "    bufferCompleteA[nextSample:destEnd] = bufferAMax[startIndex:sourceEnd]\n",
    "    bufferCompleteB[nextSample:destEnd] = bufferBMax[startIndex:sourceEnd]\n",
    "    bufferCompleteC[nextSample:destEnd] = bufferCMax[startIndex:sourceEnd]\n",
    "    bufferCompleteD[nextSample:destEnd] = bufferDMax[startIndex:sourceEnd]\n",
    "    bufferCompleteE[nextSample:destEnd] = bufferEMax[startIndex:sourceEnd]\n",
    "    nextSample += noOfSamples\n",
    "    if autoStop:\n",
    "        autoStopOuter = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-greek",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:08:14.411113Z",
     "start_time": "2021-04-19T12:07:21.686727Z"
    },
    "id": "intermediate-greek",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for itr in range(0, 5):\n",
    "    print('iteration number: ', itr+1)\n",
    "\n",
    "\n",
    "    def getArduinoData():\n",
    "        global Ox, Oy, Oz, Ax, Ay, Az, T\n",
    "        arduinoData=serial.Serial('com3',115200)\n",
    "        time.sleep(0.5)\n",
    "        n=0\n",
    "        g = [0.0, 0.0, 0.0]\n",
    "\n",
    "        while (n<950):\n",
    "            while (arduinoData.inWaiting()==0):\n",
    "                pass\n",
    "\n",
    "            dataPacket=arduinoData.readline()\n",
    "\n",
    "            dataPacket=str(dataPacket,'utf-8')\n",
    "            splitPacket=dataPacket.split(',')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            dateTimeObj = datetime.now()\n",
    "            A_x=float(splitPacket[0])\n",
    "            A_y=float(splitPacket[1])\n",
    "            A_z=float(splitPacket[2])\n",
    "            Pitch=float(splitPacket[3])\n",
    "            Roll=float(splitPacket[4])\n",
    "            Yaw=float(splitPacket[5])\n",
    "            q0=float(splitPacket[6])\n",
    "            q1=float(splitPacket[7])\n",
    "            q2=float(splitPacket[8])\n",
    "            q3=float(splitPacket[9])\n",
    "            g[0] = 2 * (q1 * q3 - q0 * q2)\n",
    "            g[1] = 2 * (q0 * q1 + q2 * q3)\n",
    "            g[2] = q0 * q0 - q1 * q1 - q2 * q2 + q3 * q3\n",
    "            Acc_x = A_x - g[0]\n",
    "            Acc_y = A_y - g[1]\n",
    "            Acc_z = A_z - g[2]\n",
    "    #         print(\"             HH:SS:MS    :     \", dateTimeObj.minute, ':', dateTimeObj.second, ':', dateTimeObj.microsecond)\n",
    "    #         print(\"AccX=\",A_x, \"             AccY = \",A_y, \"        AccZ = \",A_z)\n",
    "    #         print(\"Pitch = \",Pitch,\"        Roll = \",Roll,\"       Yaw = \",Yaw,\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            Ax = np.append (Ax, Acc_x)                    #-------------row-------------#\n",
    "            Ay = np.append (Ay, Acc_y)                    #-------------row-------------#\n",
    "            Az = np.append (Az, Acc_z)                    #-------------row-------------#\n",
    "\n",
    "            Ox = np.append (Ox, Pitch)                  #-------------row-------------#\n",
    "            Oy = np.append (Oy, Roll)                   #-------------row-------------#\n",
    "            Oz = np.append (Oz, Yaw)                    #-------------row-------------#\n",
    "\n",
    "\n",
    "            n = n+1      \n",
    "        DOx = (Ox[n-1]-Ox[0])\n",
    "        DOy = (Oy[n-1]-Oy[0])\n",
    "        DOz = (Oz[n-1]-Oz[0])\n",
    "\n",
    "        DAx = (Ox[n-1]-Ox[0])\n",
    "        DAy = (Oy[n-1]-Oy[0])\n",
    "        DAz = (Oz[n-1]-Oz[0])\n",
    "\n",
    "\n",
    "        return [Ox, Oy, Oz, Ax, Ay, Az]\n",
    "\n",
    "\n",
    "    def getHPdata():\n",
    "        global nextSample, channelA, channelB, channelC, channelD, channelE, T\n",
    "            # Set data buffer location for data collection from channel A\n",
    "        # handle = chandle\n",
    "        # source = PS4000A_CHANNEL_A = 0\n",
    "        # pointer to buffer max = ctypes.byref(bufferAMax)\n",
    "        # pointer to buffer min = ctypes.byref(bufferAMin)\n",
    "        # buffer length = maxSamples\n",
    "        # segment index = 0\n",
    "        # ratio mode = PS4000A_RATIO_MODE_NONE = 0\n",
    "        status[\"setDataBuffersA\"] = ps.ps4000aSetDataBuffers(chandle,\n",
    "                                                            ps.PS4000A_CHANNEL['PS4000A_CHANNEL_A'],\n",
    "                                                            bufferAMax.ctypes.data_as(ctypes.POINTER(ctypes.c_int16)),\n",
    "                                                            None,\n",
    "                                                            sizeOfOneBuffer,\n",
    "                                                            memory_segment,\n",
    "                                                            ps.PS4000A_RATIO_MODE['PS4000A_RATIO_MODE_NONE'])\n",
    "        assert_pico_ok(status[\"setDataBuffersA\"])\n",
    "\n",
    "        # Set data buffer location for data collection from channel B\n",
    "        # handle = chandle\n",
    "        # source = PS4000A_CHANNEL_B = 1\n",
    "        # pointer to buffer max = ctypes.byref(bufferBMax)\n",
    "        # pointer to buffer min = ctypes.byref(bufferBMin)\n",
    "        # buffer length = maxSamples\n",
    "        # segment index = 0\n",
    "        # ratio mode = PS4000A_RATIO_MODE_NONE = 0\n",
    "        status[\"setDataBuffersB\"] = ps.ps4000aSetDataBuffers(chandle,\n",
    "                                                            ps.PS4000A_CHANNEL['PS4000A_CHANNEL_B'],\n",
    "                                                            bufferBMax.ctypes.data_as(ctypes.POINTER(ctypes.c_int16)),\n",
    "                                                            None,\n",
    "                                                            sizeOfOneBuffer,\n",
    "                                                            memory_segment,\n",
    "                                                            ps.PS4000A_RATIO_MODE['PS4000A_RATIO_MODE_NONE'])\n",
    "        assert_pico_ok(status[\"setDataBuffersB\"])\n",
    "\n",
    "\n",
    "        # Set data buffer location for data collection from channel C\n",
    "        # handle = chandle\n",
    "        # source = PS4000A_CHANNEL_C = 2\n",
    "        # pointer to buffer max = ctypes.byref(bufferCMax)\n",
    "        # pointer to buffer min = ctypes.byref(bufferDMin)\n",
    "        # buffer length = maxSamples\n",
    "        # segment index = 0\n",
    "        # ratio mode = PS4000A_RATIO_MODE_NONE = 0\n",
    "        status[\"setDataBuffersC\"] = ps.ps4000aSetDataBuffers(chandle,\n",
    "                                                            ps.PS4000A_CHANNEL['PS4000A_CHANNEL_C'],\n",
    "                                                            bufferCMax.ctypes.data_as(ctypes.POINTER(ctypes.c_int16)),\n",
    "                                                            None,\n",
    "                                                            sizeOfOneBuffer,\n",
    "                                                            memory_segment,\n",
    "                                                            ps.PS4000A_RATIO_MODE['PS4000A_RATIO_MODE_NONE'])\n",
    "        assert_pico_ok(status[\"setDataBuffersC\"])\n",
    "\n",
    "        # Set data buffer location for data collection from channel D\n",
    "        # handle = chandle\n",
    "        # source = PS4000A_CHANNEL_D = 3\n",
    "        # pointer to buffer max = ctypes.byref(bufferDMax)\n",
    "        # pointer to buffer min = ctypes.byref(bufferDMin)\n",
    "        # buffer length = maxSamples\n",
    "        # segment index = 0\n",
    "        # ratio mode = PS4000A_RATIO_MODE_NONE = 0\n",
    "        status[\"setDataBuffersD\"] = ps.ps4000aSetDataBuffers(chandle,\n",
    "                                                            ps.PS4000A_CHANNEL['PS4000A_CHANNEL_D'],\n",
    "                                                            bufferDMax.ctypes.data_as(ctypes.POINTER(ctypes.c_int16)),\n",
    "                                                            None,\n",
    "                                                            sizeOfOneBuffer,\n",
    "                                                            memory_segment,\n",
    "                                                            ps.PS4000A_RATIO_MODE['PS4000A_RATIO_MODE_NONE'])\n",
    "        assert_pico_ok(status[\"setDataBuffersD\"])\n",
    "\n",
    "\n",
    "        # Set data buffer location for data collection from channel E\n",
    "        # handle = chandle\n",
    "        # source = PS4000A_CHANNEL_E = 4\n",
    "        # pointer to buffer max = ctypes.byref(bufferEMax)\n",
    "        # pointer to buffer min = ctypes.byref(bufferEMin)\n",
    "        # buffer length = maxSamples\n",
    "        # segment index = 0\n",
    "        # ratio mode = PS4000A_RATIO_MODE_NONE = 0\n",
    "\n",
    "\n",
    "        status[\"setDataBuffersE\"] = ps.ps4000aSetDataBuffers(chandle,\n",
    "                                                            ps.PS4000A_CHANNEL['PS4000A_CHANNEL_E'],\n",
    "                                                            bufferEMax.ctypes.data_as(ctypes.POINTER(ctypes.c_int16)),\n",
    "                                                            None,\n",
    "                                                            sizeOfOneBuffer,\n",
    "                                                            memory_segment,\n",
    "                                                            ps.PS4000A_RATIO_MODE['PS4000A_RATIO_MODE_NONE'])\n",
    "        assert_pico_ok(status[\"setDataBuffersE\"])\n",
    "\n",
    "\n",
    "\n",
    "        # Begin streaming mode:\n",
    "        sampleInterval = ctypes.c_int32(10)\n",
    "        sampleUnits = ps.PS4000A_TIME_UNITS['PS4000A_US']\n",
    "        # We are not triggering:\n",
    "        maxPreTriggerSamples = 0\n",
    "        autoStopOn = 1\n",
    "        # No downsampling:\n",
    "        downsampleRatio = 1\n",
    "\n",
    "\n",
    "        status[\"runStreaming\"] = ps.ps4000aRunStreaming(chandle,\n",
    "                                                        ctypes.byref(sampleInterval),\n",
    "                                                        sampleUnits,\n",
    "                                                        maxPreTriggerSamples,\n",
    "                                                        totalSamples,\n",
    "                                                        autoStopOn,\n",
    "                                                        downsampleRatio,\n",
    "                                                        ps.PS4000A_RATIO_MODE['PS4000A_RATIO_MODE_NONE'],\n",
    "                                                        sizeOfOneBuffer)\n",
    "        assert_pico_ok(status[\"runStreaming\"])\n",
    "\n",
    "\n",
    "        actualSampleInterval = sampleInterval.value\n",
    "        actualSampleIntervalNs = actualSampleInterval * 1000\n",
    "\n",
    "        print(\"Capturing at sample interval %s us\" % actualSampleInterval)\n",
    "\n",
    "\n",
    "        # We need a big buffer, not registered with the driver, to keep our complete capture in.\n",
    "        bufferCompleteA = np.zeros(shape=totalSamples, dtype=np.int16)\n",
    "        bufferCompleteB = np.zeros(shape=totalSamples, dtype=np.int16)\n",
    "        bufferCompleteC = np.zeros(shape=totalSamples, dtype=np.int16)\n",
    "        bufferCompleteD = np.zeros(shape=totalSamples, dtype=np.int16)\n",
    "        bufferCompleteE = np.zeros(shape=totalSamples, dtype=np.int16)\n",
    "        nextSample = 0\n",
    "        autoStopOuter = False\n",
    "        wasCalledBack = False\n",
    "\n",
    "\n",
    "        def streaming_callback(handle, noOfSamples, startIndex, overflow, triggerAt, triggered, autoStop, param):\n",
    "            global nextSample, autoStopOuter, wasCalledBack\n",
    "            wasCalledBack = True\n",
    "            destEnd = nextSample + noOfSamples\n",
    "            sourceEnd = startIndex + noOfSamples\n",
    "            bufferCompleteA[nextSample:destEnd] = bufferAMax[startIndex:sourceEnd]\n",
    "            bufferCompleteB[nextSample:destEnd] = bufferBMax[startIndex:sourceEnd]\n",
    "            bufferCompleteC[nextSample:destEnd] = bufferCMax[startIndex:sourceEnd]\n",
    "            bufferCompleteD[nextSample:destEnd] = bufferDMax[startIndex:sourceEnd]\n",
    "            bufferCompleteE[nextSample:destEnd] = bufferEMax[startIndex:sourceEnd]\n",
    "            nextSample += noOfSamples\n",
    "            if autoStop:\n",
    "                autoStopOuter = True\n",
    "\n",
    "\n",
    "        # Convert the python function into a C function pointer.\n",
    "        cFuncPtr = ps.StreamingReadyType(streaming_callback)\n",
    "\n",
    "        # Fetch data from the driver in a loop, copying it out of the registered buffers and into our complete one.\n",
    "        while nextSample < totalSamples and not autoStopOuter:\n",
    "            wasCalledBack = False\n",
    "            status[\"getStreamingLastestValues\"] = ps.ps4000aGetStreamingLatestValues(chandle, cFuncPtr, None)\n",
    "            if not wasCalledBack:\n",
    "                # If we wereno't called back by the driver, this means no data is ready. Sleep for a short while before trying\n",
    "                # again.\n",
    "                time.sleep(0.01)\n",
    "\n",
    "\n",
    "\n",
    "        # Find maximum ADC count value\n",
    "        # handle = chandle\n",
    "        # pointer to value = ctypes.byref(maxADC)\n",
    "        maxADC = ctypes.c_int16()\n",
    "        status[\"maximumValue\"] = ps.ps4000aMaximumValue(chandle, ctypes.byref(maxADC))\n",
    "        assert_pico_ok(status[\"maximumValue\"])\n",
    "\n",
    "        # Convert ADC counts data to mV\n",
    "        adc2mVChAMax = adc2mV(bufferCompleteA, channel_range, maxADC)\n",
    "        adc2mVChBMax = adc2mV(bufferCompleteB, channel_range, maxADC)\n",
    "        adc2mVChCMax = adc2mV(bufferCompleteC, channel_range, maxADC)\n",
    "        adc2mVChDMax = adc2mV(bufferCompleteD, channel_range, maxADC)\n",
    "        adc2mVChEMax = adc2mV(bufferCompleteE, channel_range, maxADC)\n",
    "\n",
    "        arrayA = np.array(adc2mVChAMax)\n",
    "        arrayB = np.array(adc2mVChBMax)\n",
    "        arrayC = np.array(adc2mVChCMax)\n",
    "        arrayD = np.array(adc2mVChDMax)\n",
    "        arrayE = np.array(adc2mVChEMax)\n",
    "\n",
    "        # path ='D:/Amit/Codes/python/My codes/Modified streaming example/dataset_4032021/AGAIN'\n",
    "        # folder_1 = (datetime.datetime.now())\n",
    "        # fname = str(folder_1.strftime(\"%H\"))+'-'+str(folder_1.strftime(\"%M\"))+'-'+str(folder_1.strftime(\"%S\"))\n",
    "        # os.makedirs(f'{path}/{fname}')\n",
    "        # np.savetxt(f\"{path}/{fname}/ChannelA_orig.csv\", arrayA, delimiter=\",\")\n",
    "        # np.savetxt(f\"{path}/{fname}/ChannelB_orig.csv\", arrayB, delimiter=\",\")\n",
    "        # np.savetxt(f\"{path}/{fname}/ChannelC_orig.csv\", arrayC, delimiter=\",\")\n",
    "        # np.savetxt(f\"{path}/{fname}/ChannelD_orig.csv\", arrayD, delimiter=\",\")\n",
    "        # np.savetxt(f\"{path}/{fname}/ChannelE_orig.csv\", arrayE, delimiter=\",\")\n",
    "\n",
    "        channelA = arrayA\n",
    "        channelB = arrayB\n",
    "        channelC = arrayC\n",
    "        channelD = arrayD\n",
    "        channelE = arrayE\n",
    "\n",
    "        return channelA, channelB, channelC, channelD, channelE \n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        global T\n",
    "\n",
    "        start_time = time.time()\n",
    "        # creating threads\n",
    "        t1 = threading.Thread(target=getArduinoData, name='t1')\n",
    "        t2 = threading.Thread(target=getHPdata, name='t2')\n",
    "\n",
    "        # starting threads\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "\n",
    "        # wait until all threads finish\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "        end_time = time.time()\n",
    "        T = end_time - start_time\n",
    "\n",
    "        print('\\n')\n",
    "        print(\"Process p1 is alive: {}\".format(t1.is_alive()))\n",
    "        print(\"Process p2 is alive: {}\".format(t2.is_alive()))\n",
    "        print(\"Time Taken in threading: \", (time.thread_time())/2)\n",
    "        print(\"Time taken by the loop: \", T)\n",
    "        print(\"\\n\")\n",
    "        print(\"Type of t1 and t2: \", type(t1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Size of Array A: \", np.size(channelA))\n",
    "    print(\"Channel A: \", channelA)\n",
    "    print('\\n')\n",
    "    print(\"Size of Array Ax: \", np.size(Ax))\n",
    "    print(\" Ax : \", Ax)\n",
    "\n",
    "    # Plot data from channel A and B\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    plt.plot(channelA)\n",
    "    plt.title(\"Channel A from Picoscope\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(Ax)\n",
    "    plt.title(\"Ax from Arduino\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-validity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:08:14.442149Z",
     "start_time": "2021-04-19T12:08:14.413108Z"
    },
    "id": "middle-validity"
   },
   "outputs": [],
   "source": [
    "    # notes for function def stage_1(signal, winsize_zero_cross, fs, run_plot)\n",
    "    # stage 1 does the following processes:\n",
    "    # 1. filter use IIR bandpass filters\n",
    "    # 2. estimate the zero-crossing of the first peak in two stages\n",
    "    #    first of which is approximate position where first peak crosses the threshold of 10% of signal mean\n",
    "    #    second stage, wherein use curvature of the signal to estimate a more-accurate estimate of zero-crossing\n",
    "    def Est_ZC_stage_1(signal, winsize, fs, run_plot, plot_title, std_noise_multiplier):\n",
    "\n",
    "        def sum_index(index_limit, reshaped_group_results_len):\n",
    "            ind_count = 0\n",
    "            for k in range(0, index_limit):\n",
    "                ind_count = ind_count + reshaped_group_results_len[k]\n",
    "            return ind_count\n",
    "\n",
    "        def ZC_estimation(signal_h, noise_threshold, n_max_p):\n",
    "\n",
    "            # estimate out part of the signal which is > threshold\n",
    "            results = np.where(signal_h>noise_threshold, True, False)\n",
    "\n",
    "            # itertools groupby aims to group the array in groups of True and False\n",
    "            # where g is the groups and k is unique key/ value in each group\n",
    "            # size/ length of the groups is given by len(list(g)) and is stored as an np.array\n",
    "            group_results_len = np.array([len(list(g)) for k, g in itertools.groupby(results)])\n",
    "\n",
    "            # only the first value of each groups (True or False) is stored in this array - will now correspond to each group\n",
    "            # for which length are estimated previously\n",
    "            group_results_value = np.array([list(g)[0] for k, g in itertools.groupby(results)])\n",
    "\n",
    "            # indices & group-length wherein corresponding value in group_results_value is True\n",
    "            ind_of_group_results_value_for_trues = np.array(np.where(group_results_value == True))\n",
    "            group_len_counts_of_true = (group_results_len[ind_of_group_results_value_for_trues])\n",
    "\n",
    "            # indices of top n_max maximuma of group_len_counts_of_true\n",
    "            ind_n_max_group_len_counts_of_true = np.array(np.argsort(-group_len_counts_of_true))\n",
    "\n",
    "            # manipulations to match the shape of the arrays\n",
    "            group_len_counts_of_true = group_len_counts_of_true.T\n",
    "            ind_n_max_group_len_counts_of_true = ind_n_max_group_len_counts_of_true.T\n",
    "\n",
    "            # how many maxs (top-n) need to be estimated?\n",
    "            n_max = int(len(group_len_counts_of_true)*(n_max_p)/100)\n",
    "            if n_max <= 2:\n",
    "                n_max = int(len(group_len_counts_of_true))\n",
    "\n",
    "            ind_n_max_group_len_counts_of_true = np.array(ind_n_max_group_len_counts_of_true[0:n_max])\n",
    "\n",
    "            # what are the values of the top-n (sorted) group-lengths of trues?\n",
    "            values_maxes_in_group_results_len = np.array((group_len_counts_of_true[ind_n_max_group_len_counts_of_true])) \n",
    "            values_maxes_in_group_results_len = np.reshape(values_maxes_in_group_results_len, (n_max,1))\n",
    "\n",
    "            # manipulations to match the shape of the arrays\n",
    "            reshaped_group_results_len = np.reshape(group_results_len,(len(group_results_len),1))\n",
    "\n",
    "            # elementwise comparison of the arrays to estimate the starting indices of the n_max groups of True:\n",
    "            # comparison with the entire (true-false) list\n",
    "            ind_of_max_in_group_results_len = np.array(np.where(np.in1d(reshaped_group_results_len, \n",
    "                                                                    values_maxes_in_group_results_len)))\n",
    "\n",
    "            index_max_counts_of_true = np.zeros((len(ind_of_max_in_group_results_len), 1))\n",
    "            for i in range(len(ind_of_max_in_group_results_len)):\n",
    "                try:\n",
    "                    index_max_counts_of_true[i] = sum_index(ind_of_max_in_group_results_len[i, 0], \n",
    "                                                            reshaped_group_results_len)+1\n",
    "                except:\n",
    "                    index_max_counts_of_true[i] = 0\n",
    "                    break\n",
    "\n",
    "            Q_zero_cross_index = (np.min(index_max_counts_of_true[:, 0])).astype(int)\n",
    "\n",
    "            return Q_zero_cross_index\n",
    "        def plot_ZC(signal_h, Q_zero_cross_index, plot_title, winsize):\n",
    "            sig = signal_y\n",
    "            index = Q_zero_cross_index\n",
    "            fig, axs = plt.subplots(1)\n",
    "            fig.suptitle(plot_title)\n",
    "            axs.plot(sig, label = 'bandpass')\n",
    "            axs.plot(np.repeat(0, len(sig)), 'k--', label = 'zero level')\n",
    "            axs.plot(np.repeat(noise_threshold_1, len(sig)), 'r--', label = 'noise_threshold_1')\n",
    "            axs.plot(np.repeat(noise_threshold_2, len(sig)), 'b--', label = 'noise_threshold_2')\n",
    "            axs.plot(index, sig[index], 'o')\n",
    "            rect = Rectangle((index, 0), winsize*2, np.max(sig)/2, linewidth=3, edgecolor='r',facecolor='none')\n",
    "            axs.add_patch(rect)\n",
    "            axs.legend()\n",
    "\n",
    "        # filter first and then, normalise the signal for further processing\n",
    "        signal_y = filter_bandpass(signal, fs)\n",
    "\n",
    "        # estimate the envelope of the rectified signal using the hilbert transform\n",
    "        signal_h = np.abs(hilbert(signal_y))\n",
    "\n",
    "        # estimate threshold\n",
    "        threshold = (np.mean(signal_h))\n",
    "        signal_noise_h = np.where(signal_h>threshold, 0, signal_h)\n",
    "        noise_threshold_1 = np.mean(signal_noise_h) + std_noise_multiplier * np.std(signal_noise_h)\n",
    "        print('noise_threshold_1', noise_threshold_1)\n",
    "\n",
    "        # first iteration \n",
    "        n_max_p = 5\n",
    "        init_est_ZC_index = ZC_estimation(signal_h, noise_threshold_1, n_max_p)\n",
    "        print(f'init_est_ZC_index - {plot_title}', init_est_ZC_index)\n",
    "\n",
    "        # attempt to check the samples in the neighbourhood\n",
    "        hori_check_indices = np.linspace(init_est_ZC_index-winsize, init_est_ZC_index+winsize, winsize*2, dtype = int)\n",
    "        if np.all(signal_h[hori_check_indices]<10*noise_threshold_1):\n",
    "            init_est_ZC_index = ZC_estimation(signal_h, noise_threshold_1*2, n_max_p)\n",
    "\n",
    "        # attempt to check the samples in the neighbourhood by selecting a window with elevated threshold\n",
    "        noise_threshold_2 = noise_threshold_1*1.25\n",
    "        print('noise_threshold_2', noise_threshold_2)\n",
    "        second_est_ZC_index = 0\n",
    "        if signal_h[init_est_ZC_index] >= 3*noise_threshold_1:\n",
    "            # second iteration \n",
    "            n_max_p = 50\n",
    "            sub_signal = signal_h[init_est_ZC_index-winsize : init_est_ZC_index+winsize]\n",
    "            ZC_subsignal = ZC_estimation(sub_signal, noise_threshold_2, n_max_p)\n",
    "            print(f'ZC_subsignal - {plot_title}', ZC_subsignal)\n",
    "            second_est_ZC_index = init_est_ZC_index + (ZC_subsignal-winsize)\n",
    "            print(f'second_est_ZC_index - {plot_title}', second_est_ZC_index)\n",
    "\n",
    "        if second_est_ZC_index!= 0:\n",
    "            ZC_index = second_est_ZC_index\n",
    "        else:\n",
    "            ZC_index = init_est_ZC_index\n",
    "\n",
    "        if run_plot:\n",
    "            plot_ZC(signal_h, ZC_index, plot_title, winsize)\n",
    "\n",
    "        return ZC_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-export",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:08:14.723217Z",
     "start_time": "2021-04-19T12:08:14.444616Z"
    },
    "id": "ceramic-export"
   },
   "outputs": [],
   "source": [
    "    %matplotlib inline\n",
    "    #format the book\n",
    "    import book_format\n",
    "    book_format.set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-bulgarian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:08:14.726210Z",
     "start_time": "2021-04-19T12:07:18.115Z"
    },
    "id": "specialized-bulgarian"
   },
   "outputs": [],
   "source": [
    "    from filterpy.monte_carlo import systematic_resample\n",
    "    from numpy.linalg import norm\n",
    "    from numpy.random import randn\n",
    "    import scipy.stats\n",
    "\n",
    "    no_of_repeatation = 5\n",
    "    mu = [0,0,0,0,0]\n",
    "    def run_pf1(N, iters = no_of_repeatation, sensor_std_err=0.01, \n",
    "                do_plot=True,\n",
    "                xlim=(0, 10), ylim=(0, 10),zlim=(0, 10),\n",
    "                initial_x=mu):\n",
    "        landmarks = np.array([[1.70, 0.0, 0.75], [0.80, 8.85, 0.25], [0.0, 4.25, 0.55], [3.0, 4.50, 1.20]])\n",
    "        NL = len(landmarks)\n",
    "        # create gps and weights\n",
    "\n",
    "        if initial_x is not None:\n",
    "            particles = create_gaussian_particles(\n",
    "                mean=initial_x, std=(1, 1, 1, np.pi/8, np.pi/8), N=N)\n",
    "        else:\n",
    "            particles = create_uniform_particles((0,100), (0,100), (0,100), (0, 2*np.pi), (0, 2*np.pi), N)\n",
    "        weights = np.ones(N) / N\n",
    "\n",
    "\n",
    "        xs = []\n",
    "        robot_pos = gps_solve(distances_to_station, stations)\n",
    "        pinger_coordinates_multi = gps_solve(distances_to_station, stations)\n",
    "        print('robot_pos: ', robot_pos)\n",
    "        for x in range(iters):                                                                #####Control_Input#####\n",
    "            robot_pos= initial_x           #------robot_pos which is initial_x which is mu, is getting updated evry loop------#\n",
    "            # distance from robot to each landmark\n",
    "            zs = [dist_AB, dist_AC, dist_AD, dist_AE]\n",
    "\n",
    "    #         dist_to_go = ((T**2)/2)*(math.sqrt(data[3]**2 + data[4]**2 + data[5]**2))\n",
    "            Vel_x = np.trapz(data[6], dx = T)\n",
    "            Vel_y = np.trapz(data[7], dx = T)\n",
    "            Vel_z = np.trapz(data[8], dx = T)\n",
    "            dist_to_go_x = Vel_x * T\n",
    "            dist_to_go_y = Vel_y * T\n",
    "            dist_to_go_z = Vel_z * T\n",
    "            Net_dist_to_go = math.sqrt(dist_to_go_x**2 + dist_to_go_y**2 + dist_to_go_z**2)\n",
    "            print('distnace to go in X, Y and Z : ', \"{0:.3f}\".format(dist_to_go_x*100), \"{0:.3f}\".format(dist_to_go_y*100), \"{0:.3f}\".format(dist_to_go_z*100))\n",
    "            print('distance needs to be covered in 3D space: ',\"{0:.3f}\".format(Net_dist_to_go*100))\n",
    "            print('\\n')\n",
    "\n",
    "            u = [data[1], data[2], Net_dist_to_go]\n",
    "\n",
    "            predict(particles, u, std=(.02, .01, .01, .01))    \n",
    "    #         correct(N, particles, pinger_coordinates_multi)                               #----Not in use----#\n",
    "\n",
    "            # incorporate measurements\n",
    "            update(particles, weights, z=zs, R=sensor_std_err, \n",
    "                   landmarks=landmarks)\n",
    "\n",
    "            # resample if too few effective particles\n",
    "            if neff(weights) < N/2:\n",
    "                indexes = systematic_resample(weights)\n",
    "                resample_from_index(particles, weights, indexes)\n",
    "                assert np.allclose(weights, 1/N)\n",
    "            mu, var = estimate(particles, weights)\n",
    "            xs.append(mu)\n",
    "    #         print ('Calculated coordinates of pinger: ' '\\033[1m',mu)\n",
    "    #         print ('\\033[0m') \n",
    "\n",
    "        xs = np.array(xs)\n",
    "        lastbestguess = mu\n",
    "        if iters == no_of_repeatation:\n",
    "            dateTimeObj = datetime.now()\n",
    "            print(\"HH:SS:MS    :     \", dateTimeObj.minute, ':', dateTimeObj.second, ':', dateTimeObj.microsecond)\n",
    "            print('Final calculated coordinates and headings  of pinger: ''\\033[1m', mu)\n",
    "            print ('\\033[0m')\n",
    "        return mu\n",
    "\n",
    "    from numpy.random import seed\n",
    "    seed(2)\n",
    "    pinger_coordinates_multi = gps_solve(distances_to_station, stations)\n",
    "    temp_array = [pinger_coordinates_multi[0], pinger_coordinates_multi[1], pinger_coordinates_multi[2], pinger_coordinates_multi[0], 0, 0]\n",
    "\n",
    "    x = range(100)\n",
    "    for n in x:\n",
    "        if (n==0 or n%5==0):\n",
    "            initial_x = mu = temp_array    \n",
    "        mu = run_pf1(N=25000, initial_x = mu)\n",
    "    print('FINAL COORDS: ', mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-marketplace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T12:08:14.727208Z",
     "start_time": "2021-04-19T12:07:18.117Z"
    },
    "id": "eleven-marketplace"
   },
   "outputs": [],
   "source": [
    "# Stop the scope\n",
    "# handle = chandle\n",
    "status[\"stop\"] = ps.ps4000aStop(chandle)\n",
    "assert_pico_ok(status[\"stop\"])\n",
    "\n",
    "# Disconnect the scope\n",
    "# handle = chandle\n",
    "status[\"close\"] = ps.ps4000aCloseUnit(chandle)\n",
    "assert_pico_ok(status[\"close\"])\n",
    "print('Disconnected and closed')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "12-Particle-Filters_Modified_3D_2Headings_Threading_arduino_and_picoscope_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.4px",
    "left": "1181px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
